{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"qDplYgxMZ7LS","executionInfo":{"status":"ok","timestamp":1667623262021,"user_tz":-330,"elapsed":3407,"user":{"displayName":"PANJWANI PAYAL","userId":"02415303260246464293"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torchvision.transforms import ToTensor\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow\n","from torchvision.utils import save_image\n","import numpy as np\n","import cv2  \n","import random"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ye6XRHfBc4q1","outputId":"f8493613-92c0-447d-cf77-812c23f8e15e","executionInfo":{"status":"ok","timestamp":1667623293214,"user_tz":-330,"elapsed":31204,"user":{"displayName":"PANJWANI PAYAL","userId":"02415303260246464293"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"b_2yatG4ozLF","executionInfo":{"status":"ok","timestamp":1667623293216,"user_tz":-330,"elapsed":34,"user":{"displayName":"PANJWANI PAYAL","userId":"02415303260246464293"}}},"outputs":[],"source":["class Flatten(nn.Module):\n","    def forward(self, inputs):\n","        return inputs.view(inputs.size(0), -1)\n","\n","\n","class UnFlatten(nn.Module):\n","    def forward(self, inputs, size=512):\n","        return inputs.view(inputs.size(0), 128, 4, 4)\n","\n","\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","\n","        self.model = nn.Sequential(\n","            nn.Conv2d(3, 128, kernel_size=5, stride=2, padding=2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(128, 64, kernel_size=5, stride=2, padding=2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(64, 32, kernel_size=5, stride=2, padding=2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(32, 16, kernel_size=5, stride=2, padding=2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(16, 4, kernel_size=5, stride=2, padding=2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Sigmoid(),\n","        )\n","\n","    def forward(self, img):\n","        validity = self.model(img)\n","        return (validity)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"XruQE2EhpPoV","executionInfo":{"status":"ok","timestamp":1667623293217,"user_tz":-330,"elapsed":31,"user":{"displayName":"PANJWANI PAYAL","userId":"02415303260246464293"}}},"outputs":[],"source":["class ResBlock(nn.Module):\n","    def __init__(self, n_ch) -> None:\n","        super().__init__()\n","\n","        self.resblock_model = nn.Sequential(\n","            nn.Conv2d(n_ch, n_ch, kernel_size=3, bias=False, padding=1),\n","            nn.BatchNorm2d(n_ch),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","            nn.Conv2d(n_ch, n_ch, kernel_size=3, bias=False, padding=1),\n","            nn.BatchNorm2d(n_ch)\n","        )\n","\n","    def forward(self, inputs):\n","        return self.resblock_model(inputs) + inputs"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"fnj1N2GQpQM_","executionInfo":{"status":"ok","timestamp":1667623293218,"user_tz":-330,"elapsed":30,"user":{"displayName":"PANJWANI PAYAL","userId":"02415303260246464293"}}},"outputs":[],"source":["class Downscale(nn.Module):\n","    def __init__(self, in_ch, out_ch, kernel_size=3, padding=1):\n","        super().__init__()\n","        self.in_ch = in_ch\n","        self.out_ch = out_ch\n","        self.kernel_size = kernel_size\n","        self.conv = nn.Conv2d(self.in_ch, self.out_ch, kernel_size=self.kernel_size, stride=2, padding=padding)\n","        self.batch_norm = nn.BatchNorm2d(self.out_ch)\n","        self.relu = nn.LeakyReLU(0.1)\n","        self.drop = nn.Dropout2d()\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.batch_norm(x)\n","        x = self.relu(x)\n","        x = self.drop(x)\n","        return x"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"M7O8QDxFpVC-","executionInfo":{"status":"ok","timestamp":1667623293220,"user_tz":-330,"elapsed":30,"user":{"displayName":"PANJWANI PAYAL","userId":"02415303260246464293"}}},"outputs":[],"source":["class Upscale(nn.Module):\n","    def __init__(self, in_ch, out_ch, kernel_size=5, padding=2):\n","        super().__init__()\n","        self.conv = nn.ConvTranspose2d(in_ch, out_ch, kernel_size, stride=2, padding=1)\n","        self.batch_norm = nn.BatchNorm2d(out_ch)\n","        self.relu = nn.LeakyReLU(0.1)\n","        self.drop = nn.Dropout2d()\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.batch_norm(x)\n","        x = self.relu(x)\n","        x = self.drop(x)\n","        return x"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"j-AIfcrjh7IE","executionInfo":{"status":"ok","timestamp":1667623293221,"user_tz":-330,"elapsed":30,"user":{"displayName":"PANJWANI PAYAL","userId":"02415303260246464293"}}},"outputs":[],"source":["class AutoEncoder(nn.Module):\n","\n","    def __init__(self, image_channels=3, h_dim=2048, z_dim=128):\n","        super(AutoEncoder, self).__init__()\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.encoder = nn.Sequential(\n","            Downscale(image_channels, 64),\n","            Downscale(64, 128),\n","            # Downscale(128, 128),\n","            # ResBlock(128),\n","            Downscale(128, 256),\n","            # ResBlock(256),\n","            Downscale(256, 256),\n","            Downscale(256, 512),\n","            # ResBlock(512),\n","            Downscale(512, 512),\n","            Flatten(),\n","        )\n","        # ([32, 2304])\n","\n","        self.inter_layer = nn.Sequential(\n","            nn.Linear(h_dim, z_dim),\n","            nn.Linear(z_dim, z_dim),\n","            nn.Linear(z_dim, h_dim),\n","        )\n","\n","        self.decoder = nn.Sequential(\n","            UnFlatten(),\n","            # Upscale(128, 128, kernel_size=4),\n","            Upscale(128, 256, kernel_size=4),\n","            # ResBlock(256),\n","            # ResBlock(128),\n","            # ResBlock(128),\n","            Upscale(256, 256, kernel_size=4),\n","            Upscale(256, 128, kernel_size=4),\n","            # ResBlock(128),\n","            Upscale(128, 64, kernel_size=4),\n","            ResBlock(64),\n","            Upscale(64, 32, kernel_size=4),\n","            Upscale(32, 32, kernel_size=4),\n","            nn.Conv2d(32, image_channels, kernel_size=1, stride=2),\n","            nn.Sigmoid(),\n","        )\n","\n","        self.decoder_b = nn.Sequential(\n","            UnFlatten(),\n","            # Upscale(128, 128, kernel_size=4),\n","            Upscale(128, 256, kernel_size=4),\n","            # ResBlock(256),\n","            # ResBlock(128),\n","            # ResBlock(128),\n","            Upscale(256, 256, kernel_size=4),\n","            Upscale(256, 128, kernel_size=4),\n","            # ResBlock(128),\n","            Upscale(128, 64, kernel_size=4),\n","            ResBlock(64),\n","            Upscale(64, 32, kernel_size=4),\n","            Upscale(32, 32, kernel_size=4),\n","            nn.Conv2d(32, image_channels, kernel_size=1, stride=2),\n","            nn.Sigmoid(),\n","        )\n","\n","    def forward(self, x, version='a'):\n","        z = self.encoder(x)\n","        z = self.inter_layer(z)\n","        if version == 'a':\n","            z = self.decoder(z)\n","        else:\n","            z = self.decoder_b(z)\n","        return z"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"XpxGHxf-w6Wn","executionInfo":{"status":"ok","timestamp":1667623293223,"user_tz":-330,"elapsed":31,"user":{"displayName":"PANJWANI PAYAL","userId":"02415303260246464293"}}},"outputs":[],"source":["import os\n","from math import exp\n","import torch.nn.functional as F\n","from torch.autograd import Variable"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"cOcKxmodyS75","executionInfo":{"status":"ok","timestamp":1667623293224,"user_tz":-330,"elapsed":30,"user":{"displayName":"PANJWANI PAYAL","userId":"02415303260246464293"}}},"outputs":[],"source":["\n","def gaussian(window_size, sigma):\n","    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n","    return gauss / gauss.sum()\n","\n","\n","def create_window(window_size, channel):\n","    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n","    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n","    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n","    return window\n","\n","\n","def _ssim(img1, img2, window, window_size, channel, size_average=True):\n","    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\n","    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\n","\n","    mu1_sq = mu1.pow(2)\n","    mu2_sq = mu2.pow(2)\n","    mu1_mu2 = mu1 * mu2\n","\n","    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\n","    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq\n","    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\n","\n","    C1 = 0.01 ** 2\n","    C2 = 0.03 ** 2\n","\n","    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n","\n","    if size_average:\n","        return ssim_map.mean()\n","    else:\n","        return ssim_map.mean(1).mean(1).mean(1)\n","\n","# luminance , contrast , structure\n","class SSIM(torch.nn.Module):\n","    def __init__(self, window_size=11, size_average=True):\n","        super(SSIM, self).__init__()\n","        self.window_size = window_size\n","        self.size_average = size_average\n","        self.channel = 1\n","        self.window = create_window(window_size, self.channel)\n","\n","    def forward(self, img1, img2):\n","        (_, channel, _, _) = img1.size()\n","\n","        if channel == self.channel and self.window.data.type() == img1.data.type():\n","            window = self.window\n","        else:\n","            window = create_window(self.window_size, channel)\n","\n","            if img1.is_cuda:\n","                window = window.cuda(img1.get_device())\n","            window = window.type_as(img1)\n","\n","            self.window = window\n","            self.channel = channel\n","\n","        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n","\n","\n","def ssim(img1, img2, window_size=11, size_average=True):\n","    (_, channel, _, _) = img1.size()\n","    window = create_window(window_size, channel)\n","\n","    if img1.is_cuda:\n","        window = window.cuda(img1.get_device())\n","    window = window.type_as(img1)\n","\n","    return _ssim(img1, img2, window, window_size, channel, size_average)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wpXWrLhazY82","outputId":"ea69ba43-6769-4984-e4a2-ae38dfa055c0","executionInfo":{"status":"ok","timestamp":1667623414488,"user_tz":-330,"elapsed":121292,"user":{"displayName":"PANJWANI PAYAL","userId":"02415303260246464293"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["loading data...\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","print('loading data...')\n","dataset_a = datasets.ImageFolder(root=\"/content/drive/MyDrive/Minor_Project/Dataset_2/A\" ,transform=transforms.Compose([\n","    transforms.Resize((128, 128)),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.ToTensor(),])\n",")\n","\n","dataset_b = datasets.ImageFolder(root=\"/content/drive/MyDrive/Minor_Project/Dataset_2/B\", transform=transforms.Compose([\n","    transforms.Resize((128, 128)),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.ToTensor(),])\n",")\n","\n","dataloader_a = torch.utils.data.DataLoader(dataset_a, batch_size=len(dataset_a), shuffle=True)\n","dataloader_b = torch.utils.data.DataLoader(dataset_b, batch_size=len(dataset_b), shuffle=True)\n","\n","\n","train_dataset_array_a = next(iter(dataloader_a))[0].numpy()\n","train_dataset_array_b = next(iter(dataloader_b))[0].numpy()\n","\n","np.save('a.npy', train_dataset_array_a)\n","np.save('b.npy', train_dataset_array_b)\n","\n","save = True"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"ohFqAJcHQwLV","executionInfo":{"status":"ok","timestamp":1667623414489,"user_tz":-330,"elapsed":100,"user":{"displayName":"PANJWANI PAYAL","userId":"02415303260246464293"}}},"outputs":[],"source":["class Iterator:\n","    def __init__(self, dataset, batch_size=32):\n","        self.datset = dataset\n","        self.max = len(dataset)\n","        self.batch_size = batch_size\n","        self.idx = 0\n","\n","    def __iter__(self):\n","        self.idx = 0\n","        return self\n","\n","    def __next__(self):\n","        if self.idx + + self.batch_size >= self.max - 1:\n","            np.random.shuffle(self.datset)\n","            self.idx = 0\n","        self.idx += self.batch_size\n","        return self.datset[self.idx:self.idx + self.batch_size]"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g-ZLCENFjLp9","outputId":"bb0370e1-bec8-41aa-8946-8f3cfc0d3bd8","executionInfo":{"status":"ok","timestamp":1667623414490,"user_tz":-330,"elapsed":57,"user":{"displayName":"PANJWANI PAYAL","userId":"02415303260246464293"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["PosixPath('models/model.pth')"]},"metadata":{},"execution_count":12}],"source":["# 1. Create Model directory \n","from pathlib import Path # for writing file paths\n","MODEL_PATH = Path(\"models\")\n","MODEL_PATH.mkdir(parents = True, exist_ok = True) # if the directory already exists it won't throw a error after exist_ok = True\n","MODEL_PATH_2 = Path(\"models/final\")\n","MODEL_PATH_2.mkdir(parents = True, exist_ok = True)\n","\n","# 2. Create Model Save Path\n","model_name = \"model.pth\" # common convention is to save models using either .pt or .pth file extension\n","final = \"final.pth\"\n","MODEL_SAVE_PATH = MODEL_PATH / model_name # I guess / is overloaded to return a posix path when used with Path() object\n","MODEL_SAVE_PATH_2 = MODEL_PATH_2 / final\n","MODEL_SAVE_PATH"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Ri8yKu1bzUbj","executionInfo":{"status":"ok","timestamp":1667623427650,"user_tz":-330,"elapsed":13207,"user":{"displayName":"PANJWANI PAYAL","userId":"02415303260246464293"}}},"outputs":[],"source":["itera = iter(Iterator(train_dataset_array_a, 16))\n","iterb = iter(Iterator(train_dataset_array_b, 16))\n","\n","model = AutoEncoder(image_channels=3).to(device)\n","model.load_state_dict(torch.load('/content/drive/MyDrive/Minor_Project/saved_models/final.pth'))\n","\n","discriminator = Discriminator().to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","optimizer_b = torch.optim.Adam(model.parameters(), lr=1e-3)\n","\n","mse = nn.L1Loss()\n","ssim_loss = SSIM()\n","\n","\n","def dis_loss(prob_real_is_real, prob_fake_is_real):\n","    EPS = 1e-12\n","    return torch.mean(-(torch.log(prob_real_is_real + EPS) + torch.log(1 - prob_fake_is_real + EPS)))\n","\n","\n","def gen_loss(original, recon_structed, validity):\n","    ssim_l = -ssim_loss(recon_structed, original)\n","    if validity.all():\n","        gen_loss_GAN = torch.mean(-torch.log(validity + 1e-12))\n","        # gen_loss_L1 = torch.mean(torch.abs(original - recon_structed))\n","        return 5 * ssim_l + gen_loss_GAN\n","    else:\n","        return ssim_l\n","\n","\n","def train_step(images, version='a'):\n","    _decoder_image = model(images, version=version)\n","\n","    #if args.discriminator:\n","    with torch.no_grad():\n","       validity = discriminator(_decoder_image)\n","\n","    _loss = gen_loss(_decoder_image, images, validity)\n","    #else:\n","        #_loss = gen_loss(_decoder_image, images)\n","    \n","    optimizer.zero_grad()\n","    _loss.backward(retain_graph=True)\n","    optimizer.step()\n","    # if args.discriminator:\n","    validity = discriminator(_decoder_image.detach())\n","    real_dis = discriminator(images)\n","\n","    d_loss = dis_loss(real_dis, validity)\n","    optimizer_b.zero_grad()\n","    d_loss.backward(retain_graph=True)\n","    optimizer_b.step()\n","    return _loss\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"OeXZRChHNmxZ","executionInfo":{"status":"ok","timestamp":1667623427656,"user_tz":-330,"elapsed":25,"user":{"displayName":"PANJWANI PAYAL","userId":"02415303260246464293"}}},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280},"id":"c9aXZU3GwmVm","outputId":"74d21022-a4d4-4992-90c4-31fd6d52540f","executionInfo":{"status":"error","timestamp":1667623434879,"user_tz":-330,"elapsed":7245,"user":{"displayName":"PANJWANI PAYAL","userId":"02415303260246464293"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["training for 10000 steps\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-6980c16c7546>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# loss_d = train_step(images_a, version='b')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mto_print\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Epoch[{}/{}] Loss A:{}, Loss B:{} , Loss C:{} , Loss D:{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_print\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'loss_c' is not defined"]}],"source":["print('training for {} steps'.format(10000))\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","for epoch in range(10000):\n","    # for idx, (images, _) in enumerate(dataloader):\n","    a = next(itera)\n","    b = next(iterb)\n","    images_a = torch.tensor(a, device=device).float()\n","    images_a = images_a.to(device)\n","\n","    images_b = torch.tensor(b, device=device).float()\n","    images_b = images_b.to(device)\n","\n","    loss_a = train_step(images_a, version='a')\n","    loss_b = train_step(images_b, version='b')\n","    # loss_c = train_step(images_b, version='a')\n","    # loss_d = train_step(images_a, version='b') \n","\n","    to_print = \"Epoch[{}/{}] Loss A:{}, Loss B:{} , Loss C:{} , Loss D:{}\".format(epoch+1, 10000, loss_a.data, loss_b.data,loss_c.data,loss_d.data)\n","    if epoch % 100 == 0:\n","        print(to_print)\n","        model_state_dict = model.state_dict()\n","        model_name = \"model_\"+str(epoch)\n","        torch.save(obj = model.state_dict(),f = MODEL_SAVE_PATH)\n","if save:\n","    model_state_dict = model.state_dict()\n","    torch.save(obj = model.state_dict(),f = MODEL_SAVE_PATH_2)\n","else:\n","    model.load_state_dict(torch.load(torch.load(f = MODEL_SAVE_PATH_2)))"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"KWVibtCNzTDE","executionInfo":{"status":"ok","timestamp":1667623458333,"user_tz":-330,"elapsed":9,"user":{"displayName":"PANJWANI PAYAL","userId":"02415303260246464293"}}},"outputs":[],"source":["from google.colab import files\n","# files.download(\"/content/drive/MyDrive/Minor_Project/saved_models/final.pth\")"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"ad4NrOMx4egO","executionInfo":{"status":"ok","timestamp":1667623463598,"user_tz":-330,"elapsed":1076,"user":{"displayName":"PANJWANI PAYAL","userId":"02415303260246464293"}}},"outputs":[],"source":["import os\n","from PIL import Image"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"vt_oGvDYzvta","executionInfo":{"status":"ok","timestamp":1667623472416,"user_tz":-330,"elapsed":839,"user":{"displayName":"PANJWANI PAYAL","userId":"02415303260246464293"}}},"outputs":[],"source":["def transfer(model, x, version):\n","    x = torch.from_numpy(x).unsqueeze(0)\n","    x = x.to('cuda')\n","    model.eval()\n","    if version == 'a':\n","        out = model(x, version='a')\n","        return torch.cat([x, out])\n","    elif version == 'b':\n","        out = model(x, version='b')\n","        return torch.cat([x, out])\n","\n","\n","def write_images(model, image_a, image_b, dir_name):\n","    if not os.path.exists(dir_name):\n","        os.makedirs(dir_name)\n","\n","    compare_x = transfer(model, image_a, 'a')\n","    save_image(compare_x.data.cpu(), '{}/sample_image_a.png'.format(dir_name))\n","\n","    compare_x = transfer(model, image_b, 'b')\n","    save_image(compare_x.data.cpu(), '{}/sample_image_b.png'.format(dir_name))\n","\n","    compare_x = transfer(model, image_b, 'a')\n","    save_image(compare_x.data.cpu(), '{}/sample_image_b_to_a.png'.format(dir_name))\n","\n","    compare_x = transfer(model, image_a, 'b')\n","    save_image(compare_x.data.cpu(), '{}/sample_image_a_to_b.png'.format(dir_name))"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"IpF4oXdjGlDH","executionInfo":{"status":"ok","timestamp":1667623825054,"user_tz":-330,"elapsed":1000,"user":{"displayName":"PANJWANI PAYAL","userId":"02415303260246464293"}}},"outputs":[],"source":["train_dataset_array_a = np.load(\"/content/a.npy\")\n","train_dataset_array_b = np.load(\"/content/b.npy\")\n","\n","x_a = train_dataset_array_a[random.randint(1, 10)]\n","x_b = train_dataset_array_b[random.randint(1, 10)]\n","\n","x_a = train_dataset_array_a[random.randint(1, 10)]\n","x_b = train_dataset_array_b[random.randint(1, 10)]\n","\n","write_images(model, x_a, x_b, \"/content/final_images\")"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}