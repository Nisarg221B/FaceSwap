{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"qDplYgxMZ7LS","executionInfo":{"status":"ok","timestamp":1667328172246,"user_tz":-330,"elapsed":3028,"user":{"displayName":"Nisarg Patel","userId":"14948906446985767432"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torchvision.transforms import ToTensor\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow\n","from torchvision.utils import save_image\n","import numpy as np\n","import cv2  \n","import random"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"ye6XRHfBc4q1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667328190651,"user_tz":-330,"elapsed":18410,"user":{"displayName":"Nisarg Patel","userId":"14948906446985767432"}},"outputId":"00473a14-dbd6-49c8-f98f-35c25b29c763"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["class Flatten(nn.Module):\n","    def forward(self, inputs):\n","        return inputs.view(inputs.size(0), -1)\n","\n","\n","class UnFlatten(nn.Module):\n","    def forward(self, inputs, size=2048):\n","        return inputs.view(inputs.size(0), 8, 4, 4)\n","\n","\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","\n","        self.model = nn.Sequential(\n","            nn.Conv2d(3, 128, kernel_size=5, stride=2, padding=2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(128, 64, kernel_size=5, stride=2, padding=2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(64, 32, kernel_size=5, stride=2, padding=2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(32, 16, kernel_size=5, stride=2, padding=2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(16, 4, kernel_size=5, stride=2, padding=2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Sigmoid(),\n","        )\n","\n","    def forward(self, img):\n","        validity = self.model(img)\n","        return (validity)"],"metadata":{"id":"b_2yatG4ozLF","executionInfo":{"status":"ok","timestamp":1667331042022,"user_tz":-330,"elapsed":662,"user":{"displayName":"Nisarg Patel","userId":"14948906446985767432"}}},"execution_count":73,"outputs":[]},{"cell_type":"code","source":["class ResBlock(nn.Module):\n","    def __init__(self, n_ch) -> None:\n","        super().__init__()\n","\n","        self.resblock_model = nn.Sequential(\n","            nn.Conv2d(n_ch, n_ch, kernel_size=3, bias=False, padding=1),\n","            nn.BatchNorm2d(n_ch),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","            nn.Conv2d(n_ch, n_ch, kernel_size=3, bias=False, padding=1),\n","            nn.BatchNorm2d(n_ch)\n","        )\n","\n","    def forward(self, inputs):\n","        return self.resblock_model(inputs) + inputs"],"metadata":{"id":"XruQE2EhpPoV","executionInfo":{"status":"ok","timestamp":1667331042023,"user_tz":-330,"elapsed":5,"user":{"displayName":"Nisarg Patel","userId":"14948906446985767432"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":["class Downscale(nn.Module):\n","    def __init__(self, in_ch, out_ch, kernel_size=3, padding=1):\n","        super().__init__()\n","        self.in_ch = in_ch\n","        self.out_ch = out_ch\n","        self.kernel_size = kernel_size\n","        self.conv = nn.Conv2d(self.in_ch, self.out_ch, kernel_size=self.kernel_size, stride=2, padding=padding)\n","        self.batch_norm = nn.BatchNorm2d(self.out_ch)\n","        self.relu = nn.LeakyReLU(0.1)\n","        self.drop = nn.Dropout2d()\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.batch_norm(x)\n","        x = self.relu(x)\n","        x = self.drop(x)\n","        return x"],"metadata":{"id":"fnj1N2GQpQM_","executionInfo":{"status":"ok","timestamp":1667331042652,"user_tz":-330,"elapsed":11,"user":{"displayName":"Nisarg Patel","userId":"14948906446985767432"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["class Upscale(nn.Module):\n","    def __init__(self, in_ch, out_ch, kernel_size=5, padding=2):\n","        super().__init__()\n","        self.conv = nn.ConvTranspose2d(in_ch, out_ch, kernel_size, stride=2, padding=1)\n","        self.batch_norm = nn.BatchNorm2d(out_ch)\n","        self.relu = nn.LeakyReLU(0.1)\n","        self.drop = nn.Dropout2d()\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.batch_norm(x)\n","        x = self.relu(x)\n","        x = self.drop(x)\n","        return x"],"metadata":{"id":"M7O8QDxFpVC-","executionInfo":{"status":"ok","timestamp":1667331042653,"user_tz":-330,"elapsed":12,"user":{"displayName":"Nisarg Patel","userId":"14948906446985767432"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","source":["class AutoEncoder(nn.Module):\n","\n","    def __init__(self, image_channels=3, h_dim=2048, z_dim=128):\n","        super(AutoEncoder, self).__init__()\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.encoder = nn.Sequential(\n","            Downscale(image_channels, 64),\n","            Downscale(64, 128),\n","            Downscale(128, 128),\n","            ResBlock(128),\n","            Downscale(128, 256),\n","            ResBlock(256),\n","            Downscale(256, 256),\n","            Downscale(256, 512),\n","            ResBlock(512),\n","            Downscale(512, 512),\n","            Downscale(512,1024),\n","            ResBlock(1024),\n","            Downscale(1024,1024),\n","            Downscale(1024,2048),\n","            ResBlock(2048),\n","            Downscale(2048,2048),\n","            Flatten()\n","        )\n","        # ([32, 2304])\n","\n","        self.inter_layer = nn.Sequential(\n","            nn.Linear(h_dim, z_dim),\n","            nn.Linear(z_dim, z_dim),\n","           # nn.Linear(z_dim, h_dim),\n","        )\n","\n","        self.decoder = nn.Sequential(\n","            UnFlatten(),\n","            Upscale(8, 128, kernel_size=4),\n","            Upscale(128, 256, kernel_size=4),\n","            ResBlock(256),\n","            ResBlock(128),\n","            ResBlock(128),\n","            Upscale(256, 256, kernel_size=4),\n","            Upscale(256, 128, kernel_size=4),\n","            ResBlock(128),\n","            Upscale(128, 64, kernel_size=4),\n","            ResBlock(64),\n","            Upscale(64, 32, kernel_size=4),\n","            Upscale(32, 32, kernel_size=4),\n","            nn.Conv2d(32, image_channels, kernel_size=1, stride=2),\n","            nn.Sigmoid(),\n","        )\n","\n","        self.decoder_b = nn.Sequential(\n","            UnFlatten(),\n","            Upscale(128, 128, kernel_size=4),\n","            Upscale(128, 256, kernel_size=4),\n","            ResBlock(256),\n","            ResBlock(128),\n","            ResBlock(128),\n","            Upscale(256, 256, kernel_size=4),\n","            Upscale(256, 128, kernel_size=4),\n","            ResBlock(128),\n","            Upscale(128, 64, kernel_size=4),\n","            ResBlock(64),\n","            Upscale(64, 32, kernel_size=4),\n","            Upscale(32, 32, kernel_size=4),\n","            nn.Conv2d(32, image_channels, kernel_size=1, stride=2),\n","            nn.Sigmoid(),\n","        )\n","\n","    def forward(self, x, version='a'):\n","        z = self.encoder(x)\n","        z = self.inter_layer(z)\n","        if version == 'a':\n","            z = self.decoder(z)\n","        else:\n","            z = self.decoder_b(z)\n","        return z"],"metadata":{"id":"j-AIfcrjh7IE","executionInfo":{"status":"ok","timestamp":1667331142617,"user_tz":-330,"elapsed":479,"user":{"displayName":"Nisarg Patel","userId":"14948906446985767432"}}},"execution_count":84,"outputs":[]},{"cell_type":"code","source":["import os\n","from math import exp\n","import torch.nn.functional as F\n","from torch.autograd import Variable"],"metadata":{"id":"XpxGHxf-w6Wn","executionInfo":{"status":"ok","timestamp":1667331143115,"user_tz":-330,"elapsed":7,"user":{"displayName":"Nisarg Patel","userId":"14948906446985767432"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["\n","def gaussian(window_size, sigma):\n","    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n","    return gauss / gauss.sum()\n","\n","\n","def create_window(window_size, channel):\n","    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n","    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n","    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n","    return window\n","\n","\n","def _ssim(img1, img2, window, window_size, channel, size_average=True):\n","    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\n","    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\n","\n","    mu1_sq = mu1.pow(2)\n","    mu2_sq = mu2.pow(2)\n","    mu1_mu2 = mu1 * mu2\n","\n","    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\n","    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq\n","    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\n","\n","    C1 = 0.01 ** 2\n","    C2 = 0.03 ** 2\n","\n","    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n","\n","    if size_average:\n","        return ssim_map.mean()\n","    else:\n","        return ssim_map.mean(1).mean(1).mean(1)\n","\n","\n","class SSIM(torch.nn.Module):\n","    def __init__(self, window_size=11, size_average=True):\n","        super(SSIM, self).__init__()\n","        self.window_size = window_size\n","        self.size_average = size_average\n","        self.channel = 1\n","        self.window = create_window(window_size, self.channel)\n","\n","    def forward(self, img1, img2):\n","        (_, channel, _, _) = img1.size()\n","\n","        if channel == self.channel and self.window.data.type() == img1.data.type():\n","            window = self.window\n","        else:\n","            window = create_window(self.window_size, channel)\n","\n","            if img1.is_cuda:\n","                window = window.cuda(img1.get_device())\n","            window = window.type_as(img1)\n","\n","            self.window = window\n","            self.channel = channel\n","\n","        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n","\n","\n","def ssim(img1, img2, window_size=11, size_average=True):\n","    (_, channel, _, _) = img1.size()\n","    window = create_window(window_size, channel)\n","\n","    if img1.is_cuda:\n","        window = window.cuda(img1.get_device())\n","    window = window.type_as(img1)\n","\n","    return _ssim(img1, img2, window, window_size, channel, size_average)"],"metadata":{"id":"cOcKxmodyS75","executionInfo":{"status":"ok","timestamp":1667331143115,"user_tz":-330,"elapsed":6,"user":{"displayName":"Nisarg Patel","userId":"14948906446985767432"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","print('loading data...')\n","dataset_a = datasets.ImageFolder(root=\"/content/drive/MyDrive/Minor_Project/Dataset/A\" ,transform=transforms.Compose([\n","    transforms.Resize((128, 128)),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.ToTensor(),])\n",")\n","\n","dataset_b = datasets.ImageFolder(root=\"/content/drive/MyDrive/Minor_Project/Dataset/B\", transform=transforms.Compose([\n","    transforms.Resize((128, 128)),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.ToTensor(),])\n",")\n","\n","dataloader_a = torch.utils.data.DataLoader(dataset_a, batch_size=len(dataset_a), shuffle=True)\n","dataloader_b = torch.utils.data.DataLoader(dataset_b, batch_size=len(dataset_b), shuffle=True)\n","\n","\n","train_dataset_array_a = next(iter(dataloader_a))[0].numpy()\n","train_dataset_array_b = next(iter(dataloader_b))[0].numpy()\n","\n","np.save('a.npy', train_dataset_array_a)\n","np.save('b.npy', train_dataset_array_b)\n","\n","save = True"],"metadata":{"id":"wpXWrLhazY82","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667331147340,"user_tz":-330,"elapsed":4230,"user":{"displayName":"Nisarg Patel","userId":"14948906446985767432"}},"outputId":"2b041c41-c8dd-447d-a38b-70e9629dabe8"},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["loading data...\n"]}]},{"cell_type":"code","source":["class Iterator:\n","    def __init__(self, dataset, batch_size=32):\n","        self.datset = dataset\n","        self.max = len(dataset)\n","        self.batch_size = batch_size\n","        self.idx = 0\n","\n","    def __iter__(self):\n","        self.idx = 0\n","        return self\n","\n","    def __next__(self):\n","        if self.idx + + self.batch_size >= self.max - 1:\n","            np.random.shuffle(self.datset)\n","            self.idx = 0\n","        self.idx += self.batch_size\n","        return self.datset[self.idx:self.idx + self.batch_size]"],"metadata":{"id":"ohFqAJcHQwLV","executionInfo":{"status":"ok","timestamp":1667331148007,"user_tz":-330,"elapsed":677,"user":{"displayName":"Nisarg Patel","userId":"14948906446985767432"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["# 1. Create Model directory \n","from pathlib import Path # for writing file paths\n","MODEL_PATH = Path(\"models\")\n","MODEL_PATH.mkdir(parents = True, exist_ok = True) # if the directory already exists it won't throw a error after exist_ok = True\n","MODEL_PATH_2 = Path(\"models/final\")\n","MODEL_PATH_2.mkdir(parents = True, exist_ok = True)\n","\n","# 2. Create Model Save Path\n","model_name = \"model.pth\" # common convention is to save models using either .pt or .pth file extension\n","final = \"final.pth\"\n","MODEL_SAVE_PATH = MODEL_PATH / model_name # I guess / is overloaded to reaturn a posix path when used with Path() object\n","MODEL_SAVE_PATH_2 = MODEL_PATH_2 / final\n","MODEL_SAVE_PATH"],"metadata":{"id":"g-ZLCENFjLp9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667331148008,"user_tz":-330,"elapsed":7,"user":{"displayName":"Nisarg Patel","userId":"14948906446985767432"}},"outputId":"785af8e8-e3bb-44e8-a15f-5af3f8bc942a"},"execution_count":89,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PosixPath('models/model.pth')"]},"metadata":{},"execution_count":89}]},{"cell_type":"code","source":["itera = iter(Iterator(train_dataset_array_a, 32))\n","iterb = iter(Iterator(train_dataset_array_b, 32))\n","\n","model = AutoEncoder(image_channels=3).to(device)\n","discriminator = Discriminator().to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","optimizer_b = torch.optim.Adam(model.parameters(), lr=1e-3)\n","\n","mse = nn.L1Loss()\n","ssim_loss = SSIM()\n","\n","\n","def dis_loss(prob_real_is_real, prob_fake_is_real):\n","    EPS = 1e-12\n","    return torch.mean(-(torch.log(prob_real_is_real + EPS) + torch.log(1 - prob_fake_is_real + EPS)))\n","\n","\n","def gen_loss(original, recon_structed, validity):\n","    ssim_l = -ssim_loss(recon_structed, original)\n","    if validity.all():\n","        gen_loss_GAN = torch.mean(-torch.log(validity + 1e-12))\n","        # gen_loss_L1 = torch.mean(torch.abs(original - recon_structed))\n","        return 5 * ssim_l + gen_loss_GAN\n","    else:\n","        return ssim_l\n","\n","\n","def train_step(images, version='a'):\n","    _decoder_image = model(images, version=version)\n","\n","    #if args.discriminator:\n","    with torch.no_grad():\n","       validity = discriminator(_decoder_image)\n","\n","    _loss = gen_loss(_decoder_image, images, validity)\n","    #else:\n","        #_loss = gen_loss(_decoder_image, images)\n","    \n","    optimizer.zero_grad()\n","    _loss.backward(retain_graph=True)\n","    optimizer.step()\n","    # if args.discriminator:\n","    validity = discriminator(_decoder_image.detach())\n","    real_dis = discriminator(images)\n","\n","    d_loss = dis_loss(real_dis, validity)\n","    optimizer_b.zero_grad()\n","    d_loss.backward(retain_graph=True)\n","    optimizer_b.step()\n","    return _loss\n","\n","\n","print('training for {} steps'.format(3000))\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","for epoch in range(3000):\n","    # for idx, (images, _) in enumerate(dataloader):\n","    a = next(itera)\n","    b = next(iterb)\n","    images_a = torch.tensor(a, device=device).float()\n","    images_a = images_a.to(device)\n","\n","    images_b = torch.tensor(b, device=device).float()\n","    images_b = images_b.to(device)\n","    loss_a = train_step(images_a, version='a')\n","    loss_b = train_step(images_b, version='b')\n","    to_print = \"Epoch[{}/{}] Loss A:{}, Loss B:{}\".format(epoch+1, 3000, loss_a.data, loss_b.data)\n","    if epoch % 10 == 0:\n","        print(to_print)\n","        model_state_dict = model.state_dict()\n","        model_name = \"model_\"+str(epoch)\n","        torch.save(obj = model.state_dict(),f = MODEL_SAVE_PATH)\n","if save:\n","    model_state_dict = model.state_dict()\n","    torch.save(obj = model.state_dict(),f = MODEL_SAVE_PATH_2)\n","else:\n","    model.load_state_dict(torch.load(torch.load(f = MODEL_SAVE_PATH_2)))"],"metadata":{"id":"c9aXZU3GwmVm","colab":{"base_uri":"https://localhost:8080/","height":425},"executionInfo":{"status":"error","timestamp":1667331149285,"user_tz":-330,"elapsed":1281,"user":{"displayName":"Nisarg Patel","userId":"14948906446985767432"}},"outputId":"73ed54b0-ae8d-40c6-fb3c-6dcef9317039"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["training for 3000 steps\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-90-311e34ac9e74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mimages_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mimages_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mloss_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0mloss_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mto_print\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Epoch[{}/{}] Loss A:{}, Loss B:{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-90-311e34ac9e74>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(images, version)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0m_decoder_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m#if args.discriminator:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-84-42a2384a0a04>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, version)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minter_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-74-4fc03e8806a4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresblock_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    453\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 454\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [128, 128, 3, 3], expected input[32, 256, 16, 16] to have 128 channels, but got 256 channels instead"]}]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"/content/models/final/final.pth\")"],"metadata":{"id":"KWVibtCNzTDE","executionInfo":{"status":"aborted","timestamp":1667331149286,"user_tz":-330,"elapsed":7,"user":{"displayName":"Nisarg Patel","userId":"14948906446985767432"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from PIL import Image"],"metadata":{"id":"ad4NrOMx4egO","executionInfo":{"status":"aborted","timestamp":1667331149286,"user_tz":-330,"elapsed":6,"user":{"displayName":"Nisarg Patel","userId":"14948906446985767432"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def transfer(model, x, version):\n","    x = torch.from_numpy(x).unsqueeze(0)\n","    x = x.to('cuda')\n","    model.eval()\n","    if version == 'a':\n","        out = model(x, version='a')\n","        return torch.cat([x, out])\n","    elif version == 'b':\n","        out = model(x, version='b')\n","        return torch.cat([x, out])\n","\n","\n","def write_images(model, image_a, image_b, dir_name):\n","    if not os.path.exists(dir_name):\n","        os.makedirs(dir_name)\n","\n","    compare_x = transfer(model, image_a, 'a')\n","    save_image(compare_x.data.cpu(), '{}/sample_image_a.png'.format(dir_name))\n","\n","    compare_x = transfer(model, image_b, 'b')\n","    save_image(compare_x.data.cpu(), '{}/sample_image_b.png'.format(dir_name))\n","\n","    compare_x = transfer(model, image_b, 'a')\n","    save_image(compare_x.data.cpu(), '{}/sample_image_b_to_a.png'.format(dir_name))\n","\n","    compare_x = transfer(model, image_a, 'b')\n","    save_image(compare_x.data.cpu(), '{}/sample_image_a_to_b.png'.format(dir_name))"],"metadata":{"id":"vt_oGvDYzvta","executionInfo":{"status":"aborted","timestamp":1667331149286,"user_tz":-330,"elapsed":6,"user":{"displayName":"Nisarg Patel","userId":"14948906446985767432"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = AutoEncoder(image_channels=3).to(\"cuda\")\n","model.load_state_dict(torch.load('/content/models/final/final.pth'))\n","\n","train_dataset_array_a = np.load(\"/content/a.npy\")\n","train_dataset_array_b = np.load(\"/content/b.npy\")\n","\n","x_a = train_dataset_array_a[random.randint(1, 10)]\n","x_b = train_dataset_array_b[random.randint(1, 10)]\n","\n","x_a = train_dataset_array_a[random.randint(1, 10)]\n","x_b = train_dataset_array_b[random.randint(1, 10)]\n","\n","write_images(model, x_a, x_b, \"/content/final_images\")"],"metadata":{"id":"IpF4oXdjGlDH","executionInfo":{"status":"aborted","timestamp":1667331149287,"user_tz":-330,"elapsed":7,"user":{"displayName":"Nisarg Patel","userId":"14948906446985767432"}}},"execution_count":null,"outputs":[]}]}